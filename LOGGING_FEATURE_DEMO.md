# LLM Logging & Smart Workspace Naming - Feature Demonstration

## âœ… Implementation Complete!

This document demonstrates the newly implemented comprehensive logging and smart workspace naming features.

---

## ğŸ“Š Feature 1: Comprehensive LLM Logging

### What Was Implemented

1. **New `LLMLogger` class** (`aegis/core/llm_logger.py`)
   - Logs all LLM prompts with full context
   - Logs all LLM responses with extracted content
   - Logs tool calls and file operations
   - Supports both file logging and console output (verbose mode)

2. **Integration with All Agents**
   - `CoderAgent`: Logs code generation requests and responses
   - `TesterAgent`: Logs test generation requests and responses
   - `OrchestratorAgent`: Logs planning phase interactions

3. **CLI Support**
   - New `-v` / `--verbose` flag on `aegis run` command
   - Verbose mode shows real-time LLM interactions in rich console format

### Example Output (Verbose Mode)

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [1] ğŸ“¤ PROMPT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Agent: OrchestratorAgent (Planning)                                                                           â”‚
â”‚ Model: meta-llama-3.1-8b-instruct                                                                             â”‚
â”‚ Prompt Length: 135 chars                                                                                      â”‚
â”‚ Tools: 3                                                                                                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [1] ğŸ“¥ RESPONSE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Agent: OrchestratorAgent (Planning)                                                                           â”‚
â”‚ Response Length: 174 chars                                                                                    â”‚
â”‚ Extracted: 125 chars                                                                                          â”‚
â”‚ Tool Calls: 0                                                                                                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ FILE OPERATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Operation: write_file                                                                                         â”‚
â”‚ Path: workspaces/product_model/src/models/product.py                                                          â”‚
â”‚ Status: âœ“                                                                                                     â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

### Log Files

All interactions are saved to `.aegis/llm_logs/session_YYYY-MM-DD_HH-MM-SS.log`

Example log file content:
```
================================================================================
[1] PROMPT - OrchestratorAgent (Planning) â†’ meta-llama-3.1-8b-instruct
Time: 2026-02-17T23:48:50.261251
================================================================================

SYSTEM PROMPT:
You are a planning agent. Your job: Analyze requests and create file execution plans.

TOOLS AVAILABLE: filesystem, context, shell

USER PROMPT (135 chars):
Analyze this request and create a file execution plan:

REQUEST: Create a Product model
...

--------------------------------------------------------------------------------
[1] RESPONSE - OrchestratorAgent (Planning)
Time: 2026-02-17T23:48:51.264352
Finish Reason: stop
--------------------------------------------------------------------------------

RAW RESPONSE (174 chars):
{
  "workspace_name": "product_model",
  "use_existing_workspace": false,
  "files_to_create": [...]
}
```

---

## ğŸ·ï¸ Feature 2: Smart Workspace Naming

### What Was Implemented

1. **`_generate_workspace_name()` method** in `OrchestratorAgent`
   - Extracts meaningful words from task descriptions
   - Removes common filler words (create, build, make, the, a, for, etc.)
   - Sanitizes to snake_case format
   - Limits length to 50 characters
   - Provides timestamp fallback for edge cases

2. **Enhanced Planning Prompt**
   - Updated to encourage descriptive workspace names
   - Provides examples of good naming
   - Warns against generic names like "project"

3. **Fallback Logic**
   - If LLM returns generic name ("project", "default", "workspace"), uses smart generator
   - If LLM doesn't provide workspace name, generates one automatically

### Example Transformations

| Input Description | Generated Workspace Name |
|-------------------|-------------------------|
| "Create a Product model" | `product_model` |
| "Build REST API for users" | `rest_api_users` |
| "HTML calculator app" | `html_calculator_app` |
| "Implement authentication system" | `authentication_system` |
| "make a simple todo list" | `simple_todo_list` |
| "Please create a user dashboard for me" | `user_dashboard` |

### Sanitization Features

- âœ… Removes special characters
- âœ… Converts to lowercase
- âœ… Uses underscores as separators
- âœ… Removes consecutive underscores
- âœ… Trims leading/trailing underscores
- âœ… Limits to 50 characters
- âœ… Cuts at word boundaries to avoid truncating mid-word

---

## ğŸ§ª Testing

### All Tests Passing âœ…

```
tests/test_llm_logger.py::test_llm_logger_initialization PASSED                      [  7%]
tests/test_llm_logger.py::test_llm_logger_prompt_logging PASSED                      [ 14%]
tests/test_llm_logger.py::test_llm_logger_response_logging PASSED                    [ 21%]
tests/test_llm_logger.py::test_llm_logger_file_operation_logging PASSED              [ 28%]
tests/test_llm_logger.py::test_llm_logger_tool_call_logging PASSED                   [ 35%]
tests/test_llm_logger.py::test_llm_logger_session_summary PASSED                     [ 42%]
tests/test_llm_logger.py::test_coder_agent_has_llm_logger PASSED                     [ 50%]
tests/test_llm_logger.py::test_tester_agent_has_llm_logger PASSED                    [ 57%]
tests/test_llm_logger.py::test_orchestrator_agent_has_llm_logger PASSED              [ 64%]
tests/test_llm_logger.py::test_workspace_name_generation PASSED                      [ 71%]
tests/test_llm_logger.py::test_workspace_name_removes_filler_words PASSED            [ 78%]
tests/test_llm_logger.py::test_workspace_name_fallback PASSED                        [ 85%]
tests/test_llm_logger.py::test_workspace_name_length_limit PASSED                    [ 92%]
tests/test_llm_logger.py::test_workspace_name_sanitization PASSED                    [100%]

14 passed, 1 warning in 0.57s
```

---

## ğŸ“ Usage Examples

### Enable Verbose Logging

```bash
# Run with verbose LLM logging
aegis run "Create a User model" -v

# Or use the long form
aegis run "Create a User model" --verbose
```

### View Log Files

```bash
# Logs are stored in .aegis/llm_logs/
ls -la .aegis/llm_logs/

# View a specific session
cat .aegis/llm_logs/session_2026-02-17_23-48-50.log
```

### Workspace Naming

```bash
# This command will create workspace: workspaces/product_catalog/
aegis run "Create a product catalog"

# This command will create workspace: workspaces/user_authentication/
aegis run "Build user authentication system"

# This command will create workspace: workspaces/rest_api/
aegis run "Implement REST API"
```

---

## ğŸ¯ Success Criteria Met

âœ… **Visibility:**
- All prompts logged to file âœ“
- All responses logged to file âœ“
- Console shows real-time logging with `-v` âœ“
- Log files are human-readable âœ“
- Can trace entire execution flow âœ“

âœ… **Workspace Naming:**
- Names are descriptive and relevant âœ“
- No more "project" workspaces âœ“
- Names follow snake_case convention âœ“
- Names are under 50 characters âœ“
- Fallback works for edge cases âœ“

âœ… **Debugging:**
- Can see exactly what was sent to LLM âœ“
- Can see exactly what LLM returned âœ“
- Can identify where failures occur âœ“
- Can understand agent decision-making âœ“
- Can reproduce issues âœ“

---

## ğŸ”§ Configuration

The `.gitignore` file has been updated to exclude LLM logs:

```gitignore
.aegis/llm_logs/
```

This prevents sensitive LLM interaction data from being committed to version control.

---

## ğŸ“¦ Files Modified/Created

### Created:
- `aegis/core/llm_logger.py` - New LLM logger implementation
- `tests/test_llm_logger.py` - Comprehensive test suite

### Modified:
- `.gitignore` - Added `.aegis/llm_logs/` exclusion
- `aegis/agents/coder.py` - Added LLM logging integration
- `aegis/agents/tester.py` - Added LLM logging integration
- `aegis/agents/orchestrator.py` - Added LLM logging and smart workspace naming
- `aegis/main.py` - Added verbose flag propagation to agents

---

## ğŸš€ Next Steps

The implementation is complete and ready for use! To test it live:

1. Set up your environment with an LLM provider (Anthropic, Google, or Ollama)
2. Run: `aegis run "Create a Product model" -v`
3. Observe the verbose output in console
4. Check the log file in `.aegis/llm_logs/`
5. Verify workspace created with smart name: `workspaces/product_model/`

---

## ğŸ’¡ Benefits

1. **Better Debugging**: Full visibility into LLM interactions helps diagnose issues
2. **Improved Understanding**: See exactly how agents make decisions
3. **Training Data**: Log files can be used for future model fine-tuning
4. **Better Organization**: Smart workspace names make projects more discoverable
5. **Professional Output**: No more generic "project" directories
